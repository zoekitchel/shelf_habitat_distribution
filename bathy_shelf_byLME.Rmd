---
title: "Starting with Bathy for Shelves"
output: html_notebook
---

```{r setup}
library(raster)
library(rgdal)
library(sf)
library(ncdf4)
library(rmapshaper)
library(tidyverse)
library(diptest)
library(moments)
library(viridis) #colors
library(data.table)
library(hydroTSM) #hypsometric curves
library(gridExtra)
library(ggfortify)
library(rgeos)
library(ggridges) #allows for gradient in density plot
library(psych) #summary statistics

etopo_shelf_df <- readRDS("~/Documents/grad school/Rutgers/Repositories/shelf_habitat_distribution/etopo_shelf_df.rds")
#bring in bathy for shelf regions

#LMEs
LME_spdf <- readOGR("LME66/LMEs66.shp")


#get rid of Antarctica and the arctic
LME_spdf <- LME_spdf[LME_spdf$LME_NUMBER != 61 & LME_spdf$LME_NUMBER != 64,]

#equal area projection
eaproj <- CRS("+proj=laea")
LME_spdf.EA <- spTransform(LME_spdf, eaproj)


```


Let's just start with one LME to get started
```{r LME_baltic}
LME_baltic <- LME_spdf[1,]
plot(LME_baltic)

center <- gCentroid(LME_baltic)
center@coords[2]
```


Make bathy layer into raster (I should see if this is different if I use equal area projection (To Do))
```{r rasterize}
proj <- crs(LME_spdf)
etopo_shelf_raster <- rasterFromXYZ(etopo_shelf_df, crs = proj)


#make figure of shelves
  #png("etopo_shelf_bathy.png", height=5, width=7, units="in", res=300)
  #plot(etopo_shelf_raster)
  #dev.off()

```

Clip raster to each individual polygon

```{r clip raster to polygon}
#crop bathy layer to LME subset
bathy_baltic_extent <- crop(etopo_shelf_raster, extent(LME_baltic))

#which areas of raster fall within borders?
bathy_baltic_mask <- mask(bathy_baltic_extent, LME_baltic)

#convert to df for plotting

  # First, to a SpatialPointsDataFrame
  bathy_baltic_pts <- rasterToPoints(bathy_baltic_mask, spatial = TRUE)
  # Then to a 'conventional' dataframe
  bathy_baltic_dt  <- data.table(data.frame(bathy_baltic_pts))

#keep depth positive  
bathy_baltic_dt[,depth := -(z)]

#fortify to plot shapefile on top
#LME_baltic_df <- fortify(LME_baltic) (don't need because indstead I make polygon to surround raster)

#To get a polygon that surrounds cells that are not NA

  # make all values the same.
  bathy_baltic_mask_1s <- reclassify(bathy_baltic_mask, cbind(-Inf, Inf, 1))
  
  # convert to polygons (you need to have package 'rgeos' installed for this to work)
  bathy_baltic_polygon_1s <- rasterToPolygons(bathy_baltic_mask_1s, dissolve=TRUE) #single polygon
  bathy_baltic_polygon <- rasterToPolygons(bathy_baltic_mask, dissolve=TRUE) #one polygon for each depth profile
  
  LME_reduced_baltic_df <- fortify(pp)

ggplot(bathy_baltic_dt) +
  geom_tile(aes(x = x, y = y, fill = depth)) +
  scale_fill_viridis(direction = -1, limits = c(0,2000)) +
  theme_classic() +
  labs(x = "Longitude", y = "Latitude", fill = "Depth (m)") +
  guides(fill = guide_colorbar(reverse = T)) +
  geom_path(data = LME_reduced_baltic_df, aes(x = long, y = lat, group = group), fill = NA, color = "black")

summary(bathy_baltic_dt)

#how to get area of raster

  #get sizes of all cells in raster [km2]
  cell_size<-area(bathy_baltic_mask, na.rm=TRUE, weights=FALSE)
  #delete NAs from vector of all raster cells
  ##NAs lie outside of the rastered region, can thus be omitted
  cell_size<-cell_size[!is.na(cell_size)]
  #compute area [km2] of all cells in geo_raster
  bathy_raster_area<-length(cell_size)*median(cell_size)
  
#Also, try using raster::area on polygon

#reproject
#The Lambert azimuthal equal-area projection is a particular mapping from a sphere to a disk. It accurately represents area in all regions of the sphere, but it does not accurately represent angles.
  equalareaprojection<- crs("+proj=laea")

  bathy_baltic_polygon_1s.EA <- spTransform(bathy_baltic_polygon_1s, equalareaprojection)
  bathy_baltic_polygon.EA <- spTransform(bathy_baltic_polygon, equalareaprojection)
  
    #get sizes of all polygons in shapefile (m^2)
  polygon_area <- area(bathy_baltic_sp.EA, dissolve = T)

  polygon_area_kms <- polygon_area/1e6

```

Will have to be creative on how to map LMEs that cross 180 longitude, ex. Aleutian Islands
```{r high longitude examples}
LME_datatable <- LME_spdf@data
LME_aleutian <- LME_spdf[LME_spdf$LME_NUMBER == 65,]

#crop bathy layer to LME subset
bathy_aleutian_extent <- crop(etopo_shelf_raster, extent(LME_aleutian))

#which areas of raster fall within borders?
bathy_aleutian_mask <- mask(bathy_aleutian_extent, LME_aleutian)

#convert to df for plotting

  # First, to a SpatialPointsDataFrame
  bathy_aleutian_pts <- rasterToPoints(bathy_aleutian_mask, spatial = TRUE)
  # Then to a 'conventional' dataframe
  bathy_aleutian_dt  <- data.table(data.frame(bathy_aleutian_pts))

#keep depth positive  
bathy_aleutian_dt[,depth := -(z)]

bathy_aleutian_dt$x_shift <- ifelse(bathy_aleutian_dt$x >0, bathy_aleutian_dt$x - 360, bathy_aleutian_dt$x)


#To get a polygon that surrounds cells that are not NA

  # make all values the same.
  r <- reclassify(bathy_aleutian_mask, cbind(-Inf, Inf, 1))
  
  # convert to polygons (you need to have package 'rgeos' installed for this to work)
  pp <- rasterToPolygons(r, dissolve=TRUE)
  
  LME_reduced_aleutian_df <- fortify(pp)
  
  
LME_reduced_aleutian_df$long_shift <- ifelse(LME_reduced_aleutian_df$long >0, LME_reduced_aleutian_df$long - 360, LME_reduced_aleutian_df$long)
  

ggplot(bathy_aleutian_dt) +
  geom_tile(aes(x = x_shift, y = y, fill = depth)) +
  scale_fill_viridis(direction = -1, limits = c(0,2000)) +
  theme_classic() +
  labs(x = "Longitude (˚E)", y = "Latitude", fill = "Depth (m)") +
  guides(fill = guide_colorbar(reverse = T)) +
  geom_path(data = LME_reduced_aleutian_df, aes(x = long_shift, y = lat, group = group), fill = NA, color = "black")

```

START HERE Hypsometric Curves or Density Curve? **THINK MORE CRITICALLY ABOUT HOW I CALCULATE AREA HERE (I brush over the issue that cell sizes vary)
-Try to make polygons with individual polygon for each depth level 
```{r hyposometric curves}
#list of values within raster
bathy_baltic_depth_list <- getValues(bathy_baltic_mask)
bathy_baltic_depth_list <- bathy_baltic_depth_list[!is.na(bathy_baltic_depth_list)]

bathy_baltic_depth_list_pos <- -1*bathy_baltic_depth_list

bathy_baltic_SGDF <- as(bathy_baltic_mask, 'SpatialGridDataFrame') # as spatial grid data frame
hypsometric(bathy_baltic_SGDF)

#dimensions of raster?
dim(bathy_baltic_mask)

#total number of cells?
cells <- dim(bathy_baltic_mask)[1]*dim(bathy_baltic_mask)[2]


#cells of each depth value in data table
bathy_baltic_bydepth <- data.table(freq(bathy_baltic_mask))

#NA cells
na_cell_count <- bathy_baltic_bydepth[is.na(value),]$count

#filled cells

cells_filled <- cells-na_cell_count

bathy_baltic_bydepth_complete <- bathy_baltic_bydepth[!is.na(value)]

#calculate percent of total area in polygon
bathy_baltic_bydepth_complete[,percent_area := count/sum(count)]


bathy_baltic_bydepth_complete[,area := percent_area*bathy_raster_area][,depth := -value]



(plot <- ggplot(data = bathy_baltic_bydepth_complete, aes(x = depth, y = area, fill = depth)) +
  geom_col(width = 5) +
    geom_smooth(method = "gam", se = F, color = "black") +
  theme_classic() +
  labs(x = "Depth (m)", y = "Area (km^2)", fill = "Depth (m)") +
  scale_y_continuous(expand = c(0, 0)) +
  scale_x_continuous(expand = c(0,0)) +
  scale_fill_gradientn(colors = rev(viridis(10)), limits = c(0, 2000)) +
  guides(position = "bottom", fill = guide_colorbar(reverse = T)))
  

ggsave(plot, filename = "Baltic_Sea.png")
```

What if we use projected shapefile instead of raster?

```{r area plot from projected shapefile}
#list of values within polygon
bathy_baltic_polygon.EA@data$depth <- -(bathy_baltic_polygon.EA@data$z)

bathy_baltic_polygon.EA@data$area_m <- area(bathy_baltic_polygon.EA)

bathy_baltic_polygon.EA@data$area_km <- bathy_baltic_polygon.EA@data$area_m/1e6

#sum of all areas
sum_area <- sum(bathy_baltic_polygon.EA@data$area_m)

#proportional areas
bathy_baltic_polygon.EA@data$prop_area <- bathy_baltic_polygon.EA@data$area_m/sum_area*100


(plot <- ggplot(data = bathy_baltic_polygon.EA@data, aes(x = depth, y = area_km, fill = depth)) +
  geom_col(width = 5) +
    geom_smooth(method = "gam", se = F, color = "black") +
  theme_classic() +
  labs(x = "Depth (m)", y = "Area (km^2)", fill = "Depth (m)") +
  scale_y_continuous(expand = c(0, 0)) +
  scale_x_continuous(expand = c(0,0)) +
  scale_fill_gradientn(colors = rev(viridis(10)), limits = c(0, 2000)) +
  guides(position = "bottom", fill = guide_colorbar(reverse = T)))
  

ggsave(plot, filename = "Baltic_Sea.png")
```
Compare both methods visually, looks pretty good
```{r}
ggplot() +
geom_point(aes(bathy_baltic_polygon.EA@data$depth, bathy_baltic_polygon.EA@data$area_km), color = "green") +
geom_point(aes(bathy_baltic_bydepth_complete$depth, bathy_baltic_bydepth_complete$area), color = "blue") +
theme_classic()

```


How to classify different LMES? Dip (Modality) & Skew
 "distributions with a dip value >0.01 and with significant (p<0.05) deviations from unimodality to the hourglass classification. 
 
 For distributions with a dip value ≤0.01, we assigned those with a Type-I skewness ≥0.5 to pyramid, 
 
 those with skewness ≤ −0.5 to inverse pyramid, 
 
 and the remainder to diamond, representing those with approximately normal distributions. 
 
 We chose skew cutoffs of 0.5 and −0.5 to capture right- and left-skewed distributions, respectively, and to bound distributions approximating symmetry."
 
Modality: In mathematics, unimodality means possessing a unique mode. More generally, unimodality means there is only a single highest value, somehow defined, of some mathematical object. (Wikipedia)

Skew: In probability theory and statistics, skewness is a measure of the asymmetry of the probability distribution of a real-valued random variable about its mean. The skewness value can be positive, zero, negative, or undefined. (Wikipedia)

"The dip test measures multimodality in a sample by the maximum difference, over all sample points, between the empirical distribution function, and the unimodal distribution function that minimizes that maximum difference."

To calculate these values for both raster and projected polygon, I need to create a list of values for depth from the polygon
```{r list of values projected polygon}
bathy_baltic_list_values_projected_poly <- list()
for (i in 1:nrow(bathy_baltic_polygon.EA@data)) {
  reps<-rep.int(bathy_baltic_polygon.EA@data$depth[i], round(bathy_baltic_polygon.EA@data$prop_area[i],4)*10000)
  bathy_baltic_list_values_projected_poly[[length(bathy_baltic_list_values_projected_poly) + 1]] <- reps
}

bathy_baltic_list_values_projected_poly_vector <- unlist(bathy_baltic_list_values_projected_poly)
hist(bathy_baltic_list_values_projected_poly_vector)
```

 
```{r dip test for unimodality}
#Computes Hartigans’ dip test statistic for testing unimodality, and additionally the modal interval.

diptest <- dip.test(bathy_baltic_depth_list_pos, simulate.p.value = TRUE, B = 2000)
p.value <- diptest$p.value

#for projected shapefile 
diptest_sp <- dip.test(bathy_baltic_list_values_projected_poly_vector, simulate.p.value = TRUE, B = 2000)
p.value_sp <- diptest_sp$p.value

diptest
diptest_sp

p.value
p.value_sp
```

Skew

* If skewness is less than -1 or greater than 1, the distribution is highly skewed.
* If skewness is between -1 and -0.5 or between 0.5 and 1, the distribution is moderately skewed.
* If skewness is between -0.5 and 0.5, the distribution is approximately symmetric.
```{r skew}
skew <- skewness(bathy_baltic_depth_list_pos, na.rm = T)
skew_sp <- skewness(bathy_baltic_list_values_projected_poly_vector)

skew
skew_sp
```


Maybe kurtosis too?

Kurtosis is a statistical measure that defines how heavily the tails of a distribution differ from the tails of a normal distribution. In other words, kurtosis identifies whether the tails of a given distribution contain extreme values.
```{r kurtosis}
kurtosis <- kurtosis(bathy_baltic_depth_list_pos, na.rm = T)
kurtosis_sp <- kurtosis(bathy_baltic_list_values_projected_poly_vector)

kurtosis
kurtosis_sp
```

Mean depth value
```{r mean depth}
mean <- mean(bathy_baltic_depth_list_pos)
mean_sp <- mean(bathy_baltic_list_values_projected_poly_vector)

mean
mean_sp
```

Possible groupings:

Shallow dominant: High positive skew, unimodal
Mid-Dominant: Relatively normal (low skew, kurtosis = 0, unimodal)
Deep-Dominant: High negative skew, unimodal
Uniform: kurtosis < -1.2, unimodal, little skew (None fit here, got rid of it)
Hourglass: Bimodality

Text to add to plot:
 - class
 - skew
 - dip
 - mean
 - bottleneck

```{r full plot}

plot +
  annotate("text", x = 300, y = 4000, label = paste0("Dip Test: ", signif(diptest$statistic,2), " P-value = ", signif(p.value))) +
  annotate("text", x = 300, y = 3700, label = paste0("Skew: ", round(skew,2))) +
  annotate("text", x = 300, y = 3400, label = paste0("Kurtosis: ",round(kurtosis,2))) +
  annotate("text", x = 300, y = 3100, label = paste0("Mean: ",round(mean,2), " m")) +
  geom_vline(xintercept = mean, color = "red")
```
Let's try this sequence again for the East Greenland Shelf to see if it's significantly different because it's a high latitude area
```{r testing East Greenland Shelf prepping shapefile and rasters}

  LME_east_greenland <- LME_spdf[51,]
  
  #extract centroid latitude value
  centroid <- gCentroid(LME_east_greenland)
centroid@coords[2]
  
  #clip raster to LME
  LME_extent <- crop(etopo_shelf_raster, extent(LME_east_greenland))
  
  #which areas of raster fall within borders?
  LME_greenland_mask <- mask(LME_extent, LME_east_greenland)
  
  LME_greenland_mask_1s <- reclassify(LME_greenland_mask, c(-Inf, Inf, 1)) #this raster is only 1s
  
```

```{r calculating raster size for greenland}  
  #size of raster cells, and subsequently raster
  #cell size varies quite tremendously across Greenland!! (2.03 km^2 to 6.9 km^2)
  #get sizes of all cells in raster [km2]
    cell_size<-area(LME_greenland_mask, na.rm=TRUE, weights=FALSE)
    #delete NAs from vector of all raster cells
    ##NAs lie outside of the rastered region, can thus be omitted
    cell_size<-cell_size[!is.na(cell_size)]
    #compute area [km2] of all cells in geo_raster
    greenland_raster_area<-length(cell_size)*median(cell_size)
  
```

Next, I need to construct hypsometric plots. One problem is that a value of 30 m in one cell does not necessarily mean the same as a 30 m value in another cell if those cells are different sizes. Can I somehow weight by cell size?
```{r list of values in raster}
    #list of values within raster
  greenland_bathy_depth_list <- getValues(LME_greenland_mask)
  greenland_bathy_depth_list <- greenland_bathy_depth_list[!is.na(greenland_bathy_depth_list)] #get rid of NA's
  
  greenland_bathy_depth_list_pos <- -1*greenland_bathy_depth_list


  #cells of each depth value in data table
  greenland_bathy_bydepth <- data.table(freq(LME_greenland_mask))
  
  greenland_bathy_bydepth_complete <- greenland_bathy_bydepth[!is.na(value)]
  
  #calculate percent of total area in polygon
  greenland_bathy_bydepth_complete[,percent_area := count/sum(count)] #assuming that all cells are the same size
  
  
  greenland_bathy_bydepth_complete[,area := percent_area*greenland_raster_area][,depth := -value]
  
  
  
ggplot(data = greenland_bathy_bydepth_complete, aes(x = depth, y = area, fill = depth)) +
    geom_col(width = 5) +
#    geom_smooth(method = "gam", se = F, color = "black", size = 1) +
    theme_classic() +
    labs(x = "Depth (m)", y = expression(paste("Area (", km^{2},")")), fill = "Depth (m)") +
    scale_y_continuous(expand = c(0, 0)) +
    scale_x_continuous(expand = c(0,0)) +
    scale_fill_gradientn(colors = rev(viridis(5)), limits = c(0, 2000)) +
    guides(position = "bottom", fill = guide_colorbar(reverse = T))
  
```

Greenland Test statistic calculations for classification
```{r test statistics greenland raster}
  #unimodality
  #Computes Hartigans’ dip test statistic for testing unimodality, and additionally the modal interval.
  
  diptest <- dip.test(greenland_bathy_depth_list_pos, simulate.p.value = TRUE, B = 2000)
diptest$statistic[1]
  p.value <- diptest$p.value
p.value
  skew <- skewness(greenland_bathy_depth_list_pos, na.rm = T)
skew
  kurtosis <- kurtosis(greenland_bathy_depth_list_pos, na.rm = T)
kurtosis
  mean <- mean(greenland_bathy_depth_list_pos)
mean
  max_depth <- max(greenland_bathy_depth_list_pos)
max_depth
  median_depth <- median(greenland_bathy_depth_list_pos)
median_depth

```

Area for polygon instead
```{r area for Polygon instead}

#POLYGON MAY BE THE WAY TO GO BECAUSE CELL SIZE VARIES SO MUCH

  #raster back to polygon
  LME_greenland.sp <- rasterToPolygons(LME_greenland_mask, dissolve = T) #dissolve means all same values are one polygon feature
  LME_greenland_1s.sp <- rasterToPolygons(LME_greenland_mask_1s, dissolve = T)
  
  #transform to equal area projection
  LME_greenland.EA <- spTransform(LME_greenland.sp, equalareaprojection)
  LME_greenland_1s.EA <- spTransform(LME_greenland_1s.sp, equalareaprojection)
  
#list of values within polygon (what's the best way to do this? not immediately sure)
LME_greenland.EA@data$depth <- -(LME_greenland.EA@data$z) #creating depth column in m

LME_greenland.EA@data$area_m <- area(LME_greenland.EA, dissolve = T) #calculating area in m^2 of each depth within polygon

LME_greenland.EA@data$area_km <- LME_greenland.EA@data$area_m/1e6 #convert to km^2 (same units as raster)

```

```{r calculating statistics for Greenland}
#here I have a frequency table (depth versus km^2), how do I calculate statistics? I will try equate package
library(equate)

greenland_polygon_statistics <- as.freqtab(LME_greenland.EA@data[,c(2:3)])

#statistics
  diptest_polygon <- dip.test(greenland_polygon_statistics, simulate.p.value = TRUE, B = 2000) #not sure this is doing what it should be...
diptest_polygon$statistic[1]
  p.value_polygon <- diptest_polygon$p.value
p.value_polygon
  skew_polygon <- skew.freqtab(greenland_polygon_statistics)
skew_polygon
  kurtosis_polygon <- kurt.freqtab(greenland_polygon_statistics)
kurtosis_polygon
  mean_polygon <- mean(greenland_polygon_statistics)
mean_polygon
  max_depth_polygon <- max(greenland_polygon_statistics)
max_depth_polygon
  median_depth_polygon <- median(greenland_polygon_statistics)
median_depth_polygon

diptest
diptest_polygon
p.value
p.value_polygon
skew
skew_polygon
kurtosis
kurtosis_polygon
mean
mean_polygon

#these values all look pretty dang close, except for the diptest which is a little off, but still gives same result (multimodal)!

```

Let's try one more time with another high latitude region (55, Beaufort Sea)

```{r testing Beaufort prepping shapefile and rasters}

  LME_beaufort <- LME_spdf[62,]
  
  #clip raster to LME
  LME_beaufort_extent <- crop(etopo_shelf_raster, extent(LME_beaufort))
  
  #which areas of raster fall within borders?
  LME_beaufort_mask <- mask(LME_beaufort_extent, LME_beaufort)
  
  LME_beaufort_mask_1s <- reclassify(LME_beaufort_mask, c(-Inf, Inf, 1)) #this raster is only 1s
  
```

```{r calculating raster size}  
  #size of raster cells, and subsequently raster
  #cell size varies quite tremendously across Beaufort Sea!! (3.3 km^2 to 5.4 km^2)
  #get sizes of all cells in raster [km2]
    cell_size<-area(LME_beaufort_mask, na.rm=TRUE, weights=FALSE)
    #delete NAs from vector of all raster cells
    ##NAs lie outside of the rastered region, can thus be omitted
    cell_size<-cell_size[!is.na(cell_size)]
    #compute area [km2] of all cells in geo_raster
   beaufort_raster_area<-length(cell_size)*median(cell_size)
  
```

Next, I need to construct hypsometric plots. One problem is that a value of 30 m in one cell does not necessarily mean the same as a 30 m value in another cell if those cells are different sizes. Can I somehow weight by cell size?
```{r list of values in raster}
    #list of values within raster
  beaufort_bathy_depth_list <- getValues(LME_beaufort_mask)
  beaufort_bathy_depth_list <- beaufort_bathy_depth_list[!is.na(beaufort_bathy_depth_list)] #get rid of NA's
  
  beaufort_bathy_depth_list_pos <- -1*beaufort_bathy_depth_list


  #cells of each depth value in data table
  beaufort_bathy_bydepth <- data.table(freq(LME_beaufort_mask))
  
  beaufort_bathy_bydepth_complete <- beaufort_bathy_bydepth[!is.na(value)]
  
  #calculate percent of total area in raster
  beaufort_bathy_bydepth_complete[,percent_area := count/sum(count)] #assuming that all cells are the same size
  
  
  beaufort_bathy_bydepth_complete[,area := percent_area*beaufort_raster_area][,depth := -value]
  
  
  
ggplot(data = beaufort_bathy_bydepth_complete, aes(x = depth, y = area, fill = depth)) +
    geom_col(width = 5) +
#    geom_smooth(method = "gam", se = F, color = "black", size = 1) +
    theme_classic() +
    labs(x = "Depth (m)", y = expression(paste("Area (", km^{2},")")), fill = "Depth (m)") +
    scale_y_continuous(expand = c(0, 0)) +
    scale_x_continuous(expand = c(0,0)) +
    scale_fill_gradientn(colors = rev(viridis(5)), limits = c(0, 2000)) +
    guides(position = "bottom", fill = guide_colorbar(reverse = T))
  
```

beaufort Test statistic calculations for classification
```{r test statistics beaufort raster}
  #unimodality
  #Computes Hartigans’ dip test statistic for testing unimodality, and additionally the modal interval.
  
  diptest <- dip.test(beaufort_bathy_depth_list_pos, simulate.p.value = TRUE, B = 2000)
diptest$statistic[1]
  p.value <- diptest$p.value
p.value
  skew <- skewness(beaufort_bathy_depth_list_pos, na.rm = T)
skew
  kurtosis <- kurtosis(beaufort_bathy_depth_list_pos, na.rm = T)
kurtosis
  mean <- mean(beaufort_bathy_depth_list_pos)
mean
  max_depth <- max(beaufort_bathy_depth_list_pos)
max_depth
  median_depth <- median(beaufort_bathy_depth_list_pos)
median_depth

```

Area for polygon instead
```{r area for Polygon instead}

#POLYGON MAY BE THE WAY TO GO BECAUSE CELL SIZE VARIES SO MUCH

  #raster back to polygon
  LME_beaufort.sp <- rasterToPolygons(LME_beaufort_mask, dissolve = T) #dissolve means all same values are one polygon feature
  LME_beaufort_1s.sp <- rasterToPolygons(LME_beaufort_mask_1s, dissolve = T)
  
  #transform to equal area projection
  LME_beaufort.EA <- spTransform(LME_beaufort.sp, equalareaprojection)
  LME_beaufort_1s.EA <- spTransform(LME_beaufort_1s.sp, equalareaprojection)
  
#list of values within polygon (what's the best way to do this? not immediately sure)
LME_beaufort.EA@data$depth <- -(LME_beaufort.EA@data$z) #creating depth column in m

LME_beaufort.EA@data$area_m <- area(LME_beaufort.EA, dissolve = T) #calculating area in m^2 of each depth within polygon

LME_beaufort.EA@data$area_km <- LME_beaufort.EA@data$area_m/1e6 #convert to km^2 (same units as raster)

```

```{r calculating statistics for beaufort}
#here I have a frequency table (depth versus km^2), how do I calculate statistics? I will try equate package
library(equate)

beaufort_polygon_statistics <- as.freqtab(LME_beaufort.EA@data[,c(2:3)])

#statistics
  diptest_polygon <- dip.test(beaufort_polygon_statistics, simulate.p.value = TRUE, B = 2000) #not sure this is doing what it should be...
diptest_polygon$statistic[1]
  p.value_polygon <- diptest_polygon$p.value
p.value_polygon
  skew_polygon <- skew.freqtab(beaufort_polygon_statistics)
skew_polygon
  kurtosis_polygon <- kurt.freqtab(beaufort_polygon_statistics)
kurtosis_polygon
  mean_polygon <- mean(beaufort_polygon_statistics)
mean_polygon
  max_depth_polygon <- max(beaufort_polygon_statistics)
max_depth_polygon
  median_depth_polygon <- median(beaufort_polygon_statistics)
median_depth_polygon

diptest
diptest_polygon
p.value
p.value_polygon
skew
skew_polygon
kurtosis
kurtosis_polygon
mean
mean_polygon

#these values all look pretty dang close, except for the diptest which is quite off, but still gives same result (multimodal)!

```
None of the differences in any of these classifications would lead to different classifications

One More 66, Canadian High Arctic North Greenland

```{r testing Canadian High Arctic North Greenland prepping shapefile and rasters}

  LME_high_arctic <- LME_spdf[63,]
  
  #clip raster to LME
  LME_high_arctic_extent <- crop(etopo_shelf_raster, extent(LME_high_arctic))
  
  #which areas of raster fall within borders?
  LME_high_arctic_mask <- mask(LME_high_arctic_extent, LME_high_arctic)
  
  LME_high_arctic_mask_1s <- reclassify(LME_high_arctic_mask, c(-Inf, Inf, 1)) #this raster is only 1s
  
```

```{r calculating raster size Canadian High Arctic North Greenland}  
  #size of raster cells, and subsequently raster
  #cell size varies quite tremendously across high_arctic Sea!! (3.3 km^2 to 5.4 km^2)
  #get sizes of all cells in raster [km2]
    cell_size<-area(LME_high_arctic_mask, na.rm=TRUE, weights=FALSE)
    #delete NAs from vector of all raster cells
    ##NAs lie outside of the rastered region, can thus be omitted
    cell_size<-cell_size[!is.na(cell_size)]
    #compute area [km2] of all cells in geo_raster
   high_arctic_raster_area<-length(cell_size)*median(cell_size)
  
```

Next, I need to construct hypsometric plots. One problem is that a value of 30 m in one cell does not necessarily mean the same as a 30 m value in another cell if those cells are different sizes. Can I somehow weight by cell size?
```{r list of values in raster Canadian High Arctic North Greenland}
    #list of values within raster
  high_arctic_bathy_depth_list <- getValues(LME_high_arctic_mask)
  high_arctic_bathy_depth_list <- high_arctic_bathy_depth_list[!is.na(high_arctic_bathy_depth_list)] #get rid of NA's
  
  high_arctic_bathy_depth_list_pos <- -1*high_arctic_bathy_depth_list


  #cells of each depth value in data table
  high_arctic_bathy_bydepth <- data.table(freq(LME_high_arctic_mask))
  
  high_arctic_bathy_bydepth_complete <- high_arctic_bathy_bydepth[!is.na(value)]
  
  #calculate percent of total area in raster
  high_arctic_bathy_bydepth_complete[,percent_area := count/sum(count)] #assuming that all cells are the same size
  
  
  high_arctic_bathy_bydepth_complete[,area := percent_area*high_arctic_raster_area][,depth := -value]
  
  
  
ggplot(data = high_arctic_bathy_bydepth_complete, aes(x = depth, y = area, fill = depth)) +
    geom_col(width = 5) +
#    geom_smooth(method = "gam", se = F, color = "black", size = 1) +
    theme_classic() +
    labs(x = "Depth (m)", y = expression(paste("Area (", km^{2},")")), fill = "Depth (m)") +
    scale_y_continuous(expand = c(0, 0)) +
    scale_x_continuous(expand = c(0,0)) +
    scale_fill_gradientn(colors = rev(viridis(5)), limits = c(0, 2000)) +
    guides(position = "bottom", fill = guide_colorbar(reverse = T))
  
```

high_arctic Test statistic calculations for classification
```{r test statistics high_arctic raster Canadian High Arctic North Greenland}
  #unimodality
  #Computes Hartigans’ dip test statistic for testing unimodality, and additionally the modal interval.
  
  diptest <- dip.test(high_arctic_bathy_depth_list_pos, simulate.p.value = TRUE, B = 2000)
diptest$statistic[1]
  p.value <- diptest$p.value
p.value
  skew <- skewness(high_arctic_bathy_depth_list_pos, na.rm = T)
skew
  kurtosis <- kurtosis(high_arctic_bathy_depth_list_pos, na.rm = T)
kurtosis
  mean <- mean(high_arctic_bathy_depth_list_pos)
mean
  max_depth <- max(high_arctic_bathy_depth_list_pos)
max_depth
  median_depth <- median(high_arctic_bathy_depth_list_pos)
median_depth

```

Area for polygon instead
```{r area for Polygon instead Canadian High Arctic North Greenland}

#POLYGON MAY BE THE WAY TO GO BECAUSE CELL SIZE VARIES SO MUCH

  #raster back to polygon
  LME_high_arctic.sp <- rasterToPolygons(LME_high_arctic_mask, dissolve = T) #dissolve means all same values are one polygon feature
  LME_high_arctic_1s.sp <- rasterToPolygons(LME_high_arctic_mask_1s, dissolve = T)
  
  #transform to equal area projection
  LME_high_arctic.EA <- spTransform(LME_high_arctic.sp, equalareaprojection)
  LME_high_arctic_1s.EA <- spTransform(LME_high_arctic_1s.sp, equalareaprojection)
  
#list of values within polygon (what's the best way to do this? not immediately sure)
LME_high_arctic.EA@data$depth <- -(LME_high_arctic.EA@data$z) #creating depth column in m

LME_high_arctic.EA@data$area_m <- area(LME_high_arctic.EA, dissolve = T) #calculating area in m^2 of each depth within polygon

LME_high_arctic.EA@data$area_km <- LME_high_arctic.EA@data$area_m/1e6 #convert to km^2 (same units as raster)

```

```{r calculating statistics for Canadian High Arctic North Greenland}
#here I have a frequency table (depth versus km^2), how do I calculate statistics? I will try equate package
library(equate)

high_arctic_polygon_statistics <- as.freqtab(LME_high_arctic.EA@data[,c(2:3)])

#statistics
  diptest_polygon <- dip.test(high_arctic_polygon_statistics, simulate.p.value = TRUE, B = 2000) #not sure this is doing what it should be...
diptest_polygon$statistic[1]
  p.value_polygon <- diptest_polygon$p.value
p.value_polygon
  skew_polygon <- skew.freqtab(high_arctic_polygon_statistics)
skew_polygon
  kurtosis_polygon <- kurt.freqtab(high_arctic_polygon_statistics)
kurtosis_polygon
  mean_polygon <- mean(high_arctic_polygon_statistics)
mean_polygon
  max_depth_polygon <- max(high_arctic_polygon_statistics)
max_depth_polygon
  median_depth_polygon <- median(high_arctic_polygon_statistics)
median_depth_polygon

diptest
diptest_polygon
p.value
p.value_polygon
skew
skew_polygon
kurtosis
kurtosis_polygon
mean
mean_polygon

#Here, unfortunately it appears that the diptest is different enough between the two methods is different enough to lead to different classifications (raster --> not multimodal, polygon --> multimodal)

```
Plotting hysometric graphs to compare two methods
```{r plotting graphs for CA high arctic}

(plot_higharctic_polygon <- ggplot(data = LME_high_arctic.EA@data, aes(x = depth, y = area_km, fill = depth)) +
  geom_col(width = 5) +
  #  geom_smooth(method = "gam", se = F, color = "black") +
  theme_classic() +
  labs(x = "Depth (m)", y = "Area (km^2)", fill = "Depth (m)") +
  scale_y_continuous(expand = c(0, 0)) +
  scale_x_continuous(expand = c(0,0)) +
  scale_fill_gradientn(colors = rev(viridis(10)), limits = c(0, 2000)) +
  guides(position = "bottom", fill = guide_colorbar(reverse = T))) +
  annotate("text", x = 600, y = 1650, label = "LME 66: Canadian High Arctic: Projected Polygon") +
  annotate("text", x = 700, y = 1550, label = paste0("Dip Test: ", signif(diptest_polygon$statistic,2), " P-value = ", signif(p.value))) +
  annotate("text", x = 700, y = 1450, label = paste0("Skew: ", round(skew_polygon,2))) +
#  annotate("text", x = 700, y = 1350, label = paste0("Kurtosis: ",round(kurtosis_polygon,2))) +
  annotate("text", x = 700, y = 1250, label = paste0("Mean: ",round(mean_polygon,2), " m")) +
  annotate("text", x = 700, y = 1150, label = "Classification = Multimodal") +
  geom_vline(xintercept = mean, color = "red")

#and now for raster
(plot_higharctic_raster <- ggplot(data = high_arctic_bathy_bydepth_complete, aes(x = depth, y = area, fill = depth)) +
  geom_col(width = 5) +
  #  geom_smooth(method = "gam", se = F, color = "black") +
  theme_classic() +
  labs(x = "Depth (m)", y = "Area (km^2)", fill = "Depth (m)") +
  scale_y_continuous(expand = c(0, 0)) +
  scale_x_continuous(expand = c(0,0)) +
  scale_fill_gradientn(colors = rev(viridis(10)), limits = c(0, 2000)) +
  guides(position = "bottom", fill = guide_colorbar(reverse = T))) +
  annotate("text", x = 600, y = 1650, label = "LME 66: Canadian High Arctic: Unprojected Raster") +
  annotate("text", x = 700, y = 1550, label = paste0("Dip Test: ", signif(diptest$statistic,2), " P-value = ", signif(p.value))) +
  annotate("text", x = 700, y = 1450, label = paste0("Skew: ", round(skew,2))) +
#  annotate("text", x = 700, y = 1350, label = paste0("Kurtosis: ",round(kurtosis,2))) +
  annotate("text", x = 700, y = 1250, label = paste0("Mean: ",round(mean,2), " m")) +
  annotate("text", x = 700, y = 1150, label = "Classification = Mid-Dominant") +
  geom_vline(xintercept = mean, color = "red")

```






--------
Now let's make a loop!!

(I do not feel like I need to change )

```{r loop for caculations and classifications}

#plot map, plot hypsograph, plot histogram

#reorder LME_spdf by LME # 
LME_spdf_ordered <- LME_spdf[order(LME_spdf$LME_NUMBER),]


LME_bathy_statistics <- as.data.table(matrix(nrow = nrow(LME_spdf)))
LME_bathy_statistics[, lme_name := as.factor(V1)][, lme_number := as.numeric(V1)][,lme_area := as.numeric(V1)][, dip_test := as.numeric(V1)][, dip_p_value := as.numeric(V1)][, skew := as.numeric(V1)][, kurtosis := as.numeric(V1)][, mean_depth := as.numeric(V1)][, max_depth := as.numeric(V1)][, median_depth := as.numeric(V1)][, center_latitude := as.numeric(V1)]

LME_bathy_statistics[, V1 := NULL]


lme_maps <- vector("list", length = nrow(LME_spdf))
lme_densityplots <- vector("list", length = nrow(LME_spdf))
lme_areaplots <- vector("list", length = nrow(LME_spdf))

for (i in 1:nrow(LME_bathy_statistics)) {
  LME_single <- LME_spdf_ordered[i,]
  LME_bathy_statistics[i, "lme_name"] <- LME_single$LME_NAME
  LME_bathy_statistics[i, "lme_number"] <- LME_single$LME_NUMBER
  
  #extract centroid latitude value
  centroid <- gCentroid(LME_single)
  LME_bathy_statistics[i, "center_latitude"] <- centroid@coords[2]
  
  #clip raster to LME
  LME_extent <- crop(etopo_shelf_raster, extent(LME_single))
  
  #which areas of raster fall within borders?
  LME_mask <- mask(LME_extent, LME_single)
  
  #conver to df for plotting
    # First, to a SpatialPointsDataFrame
    LME_points <- rasterToPoints(LME_mask, spatial = TRUE)
    # Then to a 'conventional' dataframe
    LME_dt  <- data.table(data.frame(LME_points))
  
  #keep depth positive  
  LME_dt[,depth := -(z)]
  
  LME_dt$x_shift <- ifelse(
    max(LME_dt$x)-min(LME_dt$x) > 200 & LME_dt$x >0,
    LME_dt$x - 360,
    LME_dt$x)
  
  #size of raster  
  #get sizes of all cells in raster [km2]
    cell_size<-area(LME_mask, na.rm=TRUE, weights=FALSE)
    #delete NAs from vector of all raster cells
    ##NAs lie outside of the rastered region, can thus be omitted
    cell_size<-cell_size[!is.na(cell_size)]
    #compute area [km2] of all cells in geo_raster
    bathy_raster_area<-length(cell_size)*median(cell_size)
    
    LME_bathy_statistics[i, "lme_area"] <- bathy_raster_area
    
  #To get a polygon that surrounds cells that are not NA
  
    # make all values the same.
    r <- reclassify(LME_mask, cbind(-Inf, Inf, 1))
    
    # convert to polygons (you need to have package 'rgeos' installed for this to work)
    pp <- rasterToPolygons(r, dissolve=TRUE) #longest step
    
    LME_reduced_df <- fortify(pp)
    
    LME_reduced_df$long_shift <- ifelse(
    max(LME_reduced_df$long)-min(LME_reduced_df$long) > 200 & LME_reduced_df$long >0,
    LME_reduced_df$long - 360,
    LME_reduced_df$long)
  
  lme_maps[[i]] <- ggplot(LME_dt) +
    geom_tile(aes(x = x_shift, y = y, fill = depth)) +
    scale_fill_viridis(direction = -1, limits = c(0,2000)) +
    theme_classic() +
    labs(x = "Longitude", y = "Latitude", fill = "Depth (m)") +
    guides(fill = guide_colorbar(reverse = T)) +
    geom_path(data = LME_reduced_df, aes(x = long_shift, y = lat, group = group), color = "black") +
    annotate("text", x=Inf, y = max(LME_reduced_df$lat)+1, hjust=1, label = paste0("LME ", LME_bathy_statistics[i,lme_number], ": ", LME_bathy_statistics[i,lme_name]), fontface = "bold", size = 2.5)
  
  
    #list of values within raster
  LME_bathy_depth_list <- getValues(LME_mask)
  LME_bathy_depth_list <- LME_bathy_depth_list[!is.na(LME_bathy_depth_list)]
  
  LME_bathy_depth_list_pos <- -1*LME_bathy_depth_list


  #cells of each depth value in data table
  LME_bathy_bydepth <- data.table(freq(LME_mask))
  
  LME_bathy_bydepth_complete <- LME_bathy_bydepth[!is.na(value)]
  
  #calculate percent of total area in polygon
  LME_bathy_bydepth_complete[,percent_area := count/sum(count)]
  
  
  LME_bathy_bydepth_complete[,area := percent_area*bathy_raster_area][,depth := -value]
  
  
  
  lme_areaplots[[i]] <- ggplot(data = LME_bathy_bydepth_complete, aes(x = depth, y = area, fill = depth)) +
    geom_col(width = 5) +
#    geom_smooth(method = "gam", se = F, color = "black", size = 1) +
    theme_classic() +
    labs(x = "Depth (m)", y = expression(paste("Area (", km^{2},")")), fill = "Depth (m)") +
    scale_y_continuous(expand = c(0, 0)) +
    scale_x_continuous(expand = c(0,0)) +
    scale_fill_gradientn(colors = rev(viridis(5)), limits = c(0, 2000)) +
    guides(position = "bottom", fill = guide_colorbar(reverse = T))
  
  
  #unimodality
  #Computes Hartigans’ dip test statistic for testing unimodality, and additionally the modal interval.
  
  diptest <- dip.test(LME_bathy_depth_list_pos, simulate.p.value = TRUE, B = 2000)
  LME_bathy_statistics[i,"dip_test"] <- diptest$statistic[1]
  p.value <- diptest$p.value
  LME_bathy_statistics[i,"dip_p_value"] <- p.value
  skew <- skewness(LME_bathy_depth_list_pos, na.rm = T)
  LME_bathy_statistics[i,"skew"] <- skew
  kurtosis <- kurtosis(LME_bathy_depth_list_pos, na.rm = T)
  LME_bathy_statistics[i,"kurtosis"] <- kurtosis
  mean <- mean(LME_bathy_depth_list_pos)
  LME_bathy_statistics[i,"mean_depth"] <- mean
  max_depth <- max(LME_bathy_depth_list_pos)
  LME_bathy_statistics[i, "max_depth"] <- max_depth
  median_depth <- median(LME_bathy_depth_list_pos)
  LME_bathy_statistics[i, "median_depth"] <- median_depth
  
  max_area <- max(LME_bathy_bydepth_complete$area)
 
    print(paste(i, nrow(LME_bathy_statistics), sep = "/"))
  

}

saveRDS(LME_bathy_statistics, file = "LME_bathy_statistics.RData")
saveRDS(lme_densityplots, file = "lme_densityplots.Rdata")
saveRDS(lme_areaplots, file = "lme_areaplots.Rdata")
saveRDS(lme_maps, file = "lme_maps.Rdata")

#plots to pdf
ggsave("arranged_maps.pdf", marrangeGrob(lme_maps, ncol=2, nrow = 2))
#ggsave("arranged_densityplots.pdf", marrangeGrob(grobs = lme_densityplots, ncol=2, nrow = 3))
ggsave("arranged_areaplots.pdf", marrangeGrob(grobs = lme_areaplots, ncol=2, nrow = 3))
```
Associate LME with region

- keep in mind, LME 1 (1&6) and 54 (1&6) and 65 (1&6) appear in multiple

```{r LME to region}
west_pac <- c(35,	36,	37,	39,	40,	41,	42,	46,	47,	48,	49,	50,	51,	52,	53, 56,	57)
east_pac <- c(2, 3, 4, 11, 13, 55)
west_atl <- c(5, 6, 7, 8, 9, 12, 14, 15, 16, 17, 18, 63, 66)
east_atl <- c(19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 58, 59, 60, 62)
west_ind <- c(30, 31, 32, 33)
east_ind <- c(34, 38, 43, 44, 45)
east_west_pac <- c(1, 54, 65)
east_pac_west_atl <- c(61)

#OR larger groupings (includes LME's left out of earlier analyses because disconnected, aka Hawaii etc.)
pacific <- c(35,	36,	37,	39,	40,	41,	42,	46,	47,	48,	49,	50,	51,	52,	53, 56,	57, 2, 3, 4, 11, 13, 55, 1, 54, 65,10)
atlantic <- c(5, 6, 7, 8, 9, 12, 14, 15, 16, 17, 18, 63, 66, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 58, 59, 60, 62 )
indian <- c(30, 31, 32, 33, 34, 38, 43, 44, 45)
antarctica <- c(61) #excluding
arctic <- c(64) #excluding



#LME_bathy_statistics[,region := ifelse(lme_number %in% west_pac, "west_pac",ifelse(lme_number %in% east_pac, #"east_pac", ifelse(lme_number %in% west_atl, "west_atl", ifelse(lme_number %in% west_ind, "west_ind", #ifelse(lme_number %in% east_atl, "east_atl", ifelse(lme_number %in% east_ind, "east_ind", ifelse(lme_number #%in% east_west_pac, "east_west_pac", ifelse(lme_number %in% east_pac_west_atl, "east_pac_west_atl", #"none"))))))))]

LME_bathy_statistics[,region := ifelse(lme_number %in% pacific, "pacific", ifelse(lme_number %in% atlantic, "atlantic", ifelse(lme_number %in% indian, "indian", ifelse(lme_number %in% antarctica, "antarctica", "arctic"))))]

```



TO DO:
make plots into curves instead of actual data** GAM, or kernel density? maybe neither

Add classifications to data frame

* If skewness is less than -1 or greater than 1, the distribution is highly skewed.
* If skewness is between -1 and -0.5 or between 0.5 and 1, the distribution is moderately skewed.
* If skewness is between -0.5 and 0.5, the distribution is approximately symmetric.

distributions with a dip value >0.01 and with significant (p<0.05) deviations from unimodality to the hourglass classification. 

For distributions with a dip value ≤0.01, we assigned those with a Type-I skewness ≥0.5 to shallow dominant, those with skewness ≤ −0.5 to deep dominant, and the remainder to diamond, representing those with approximately normal distributions. This is what Elsen and Tingley did. Now, I'm going to play around with skew cutoff of 1 rather than 0.5.

```{r expanded dataframe}
LME_bathy_statistics[, skew_descriptor := ifelse(abs(skew) > 1, "high_skew", ifelse(abs(skew) < 0.5, "symmetric", "mod_skew"))]

LME_bathy_statistics[, hourglass := ifelse(dip_test > 0.01, ifelse(dip_p_value < 0.05, T, F), F)]

LME_bathy_statistics[, deep_dominant := ifelse(dip_test <= 0.01, 
                                               ifelse(skew <= -1, T, F), F)]

LME_bathy_statistics[, shallow_dominant := ifelse(dip_test <= 0.01, 
                                                  ifelse(skew >= 1, T, F), F)]

LME_bathy_statistics[, mid_dominant := ifelse(dip_test <= 0.01,
                                          ifelse(abs(skew) <1, T, F), F)]

#negative kurtosis (no tails)
LME_bathy_statistics[, uniform := ifelse(kurtosis < 0, T, F)]

```

Are all regions labeled by type?
```{r labeling check}
LME_bathy_statistics[,type := ifelse(hourglass == T, "Multimodal",
                                    ifelse(deep_dominant == T, "Deep Dominant",
                                           ifelse(shallow_dominant == T, "Shallow Dominant",
                                                  ifelse(mid_dominant == T, "Mid Dominant", 
                                                         ifelse(uniform == T, "Uniform", "none")))))][,lme_name2 := lme_name]

write.csv(LME_bathy_statistics, "LME_bathy_statistics.csv")
saveRDS(LME_bathy_statistics, file = "LME_bathy_statistics.RData")
```

Now that we have classified distributions, let's make final plots
```{r plots with classification and statistics}

lme_areaplots_classified <- vector("list", length = nrow(LME_bathy_statistics))

for (i in 1:nrow(LME_bathy_statistics)) {
  
  #get max y value to set label location
  ggp <- ggplot_build(lme_areaplots[[i]])
max_y <- ggp$layout$panel_scales_y[[1]]$range$range[[2]]  #y range
  
#full plot
  lme_areaplots_classified[[i]] <- lme_areaplots[[i]] +
    geom_vline(xintercept = LME_bathy_statistics[i,mean_depth], color = "red") +
    annotate("text", x=Inf, y = max_y-max_y/20, hjust=1, label = paste0("LME ", LME_bathy_statistics[i,lme_number], ": ", LME_bathy_statistics[i,lme_name]), fontface = "bold", size = 2) +
        annotate("text", x=Inf, y = max_y-2*max_y/20, hjust=1, label = paste0("Classification: ", LME_bathy_statistics[i,type]), size = 2) +
    annotate("text", x=Inf, y = max_y-3*max_y/20, hjust=1, label = paste0("Dip Test: ", signif(LME_bathy_statistics[i,dip_test],2), " P-value = ", signif(LME_bathy_statistics[i,dip_p_value], 2)), size = 2) +
    annotate("text", x=Inf, y = max_y-4*max_y/20, hjust=1, label = paste0("Skew: ", round(LME_bathy_statistics[i,skew],2)), size = 2) +
#    annotate("text", x=Inf, y = max_area-4*(max_area/20), hjust=1, label = paste0("Kurtosis: ",round(kurtosis,2)), size = 2) +
    annotate("text", x=Inf, y = max_y-5*max_y/20, hjust=1, label = paste0("Mean: ",round(LME_bathy_statistics[i,mean_depth],2), " m"), size = 2)


}

ggsave("arranged_areaplots_classified.pdf", marrangeGrob(grobs = lme_areaplots_classified, ncol=2, nrow = 3))
```


PCA

- size
- region (color)
- mean depth
- mid-latitude
- classification (color)
- max depth

```{r PCA}
library(ggfortify)
#get rid of antartica and arctic (can remove this next round)
LME_bathy_statistics <- LME_bathy_statistics[lme_number != 61,][lme_number != 64,]


LME.pca <- prcomp(LME_bathy_statistics[,.(lme_area, mean_depth, max_depth, center_latitude)], scale. = T)


LME.plot_type <- autoplot(LME.pca, data = LME_bathy_statistics, colour = 'type',
                          loadings = TRUE, loadings.colour = 'black',
                          loadings.label = TRUE, loadings.label.size = 4) + theme_classic()
LME.plot_region <- autoplot(LME.pca, data = LME_bathy_statistics, colour = 'region',
                          loadings = TRUE, loadings.colour = 'black',
                          loadings.label = TRUE, loadings.label.size = 4) + theme_classic()

LME.plot_type
LME.plot_region

ggsave(plot = LME.plot_type, filename = "LME.plot_type.pdf")
ggsave(plot = LME.plot_region, filename = "LME.plot_region.pdf")

```
How many of each type
hourglass/multimodal     mid_dominant            shallow_dominant 
       44 (69%)                8 (13%)                12 (20%) 
```{r how many of each type}
table(LME_bathy_statistics$type)
44/64 #multimodal
8/64 #mid-dominant
12/64 #shallow-dominant
```
